{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55031bb-06ae-4ebb-aeb1-87f6b62e417d",
   "metadata": {},
   "source": [
    "# ZERO SHOT\n",
    "\n",
    "Estudo de prompts compeletamente ZERO SHOT e sem estratégia definida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebc3792-3106-43a6-a8fa-386dbda56cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessários\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fad9ae-bf49-4e9b-8e86-4616d1d9a8cf",
   "metadata": {},
   "source": [
    "Utilização o llama 3.2 via interface Ollama \n",
    "Ref.:\n",
    "\n",
    "https://github.com/ollama/ollama \n",
    "\n",
    "https://ollama.com/library/llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ed353e-667f-4abd-b84c-e7842058ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b2335-5dac-4764-b158-ec35d3e1aada",
   "metadata": {},
   "source": [
    "## Verificação se a inteface está funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ad17df-ab73-4526-b5b8-76db36cbd0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Olá! Tudo bem, obrigado! Como posso ajudar você hoje?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Olá, tudo bem?\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfef36-3126-48af-9364-10c3dde7d5a9",
   "metadata": {},
   "source": [
    "## Aqui considero que a conversa **não** tem memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82bc01c8-403e-4d47-b343-aed167815004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Nada, porque essa é a nossa primeira interação. Como posso te ajudar hoje?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "O que você disse?\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14376a7f-7707-4e35-8e79-9456edf41e7d",
   "metadata": {},
   "source": [
    "## Aqui vou fazer um prompt totalmente sem estratégia (zero-shot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
