{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d55031bb-06ae-4ebb-aeb1-87f6b62e417d",
   "metadata": {},
   "source": [
    "# GuardRails - Restrição de domínio\n",
    "\n",
    "Guardrails são mecanismos (**regras, filtros e restrições**) aplicados a grandes modelos de linguagem (LLMs) para controlar e limitar seu comportamento, bloqueando conteúdos impróprios, enviesados ou inseguros e assegurando que as respostas sigam políticas de uso e padrões de segurança."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebc3792-3106-43a6-a8fa-386dbda56cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports necessários\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from IPython.display import display, Markdown\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ed353e-667f-4abd-b84c-e7842058ff7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotenv_path = Path(\"../.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7bf986c-5c98-4361-b3e6-f82c33ced699",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b2335-5dac-4764-b158-ec35d3e1aada",
   "metadata": {},
   "source": [
    "## Verificação se a inteface está funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98ad17df-ab73-4526-b5b8-76db36cbd0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*Resposta:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Olá! Tudo bem, e você? Como posso ajudar hoje?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Olá, tudo bem?\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "display(Markdown(f\"*Resposta:*\"))\n",
    "display(Markdown(f\"----\"))\n",
    "display(Markdown(f\"{response.content}\"))\n",
    "display(Markdown(f\"----\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dfef36-3126-48af-9364-10c3dde7d5a9",
   "metadata": {},
   "source": [
    "## Aqui considero que a conversa **não** tem memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82bc01c8-403e-4d47-b343-aed167815004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*Resposta:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Eu disse que sou um assistente virtual e estou aqui para ajudar com informações e responder às suas perguntas. O que você gostaria de saber?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "O que você disse?\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "display(Markdown(f\"*Resposta:*\"))\n",
    "display(Markdown(f\"----\"))\n",
    "display(Markdown(f\"{response.content}\"))\n",
    "display(Markdown(f\"----\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14376a7f-7707-4e35-8e79-9456edf41e7d",
   "metadata": {},
   "source": [
    "## **PROMPT 01:** Restrição de domínio (pergunta genérica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1beefe4-3be7-4a3b-b5fc-dc5e690b48db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*Resposta:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Esse tópico está fora do escopo de Qualidade de Software. Posso ajudar com dúvidas sobre testes, automação ou métricas de QA."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GUARDRAIL = \"\"\"\n",
    "Você só deve responder a perguntas estritamente relacionadas ao domínio de Qualidade de Software (QA), incluindo:\n",
    "- Planejamento e execução de testes (funcionais, não funcionais, unitários, integração, performance, segurança)\n",
    "- Automação de testes (ferramentas como Selenium, Cypress, JUnit, pytest etc.)\n",
    "- Estratégias de cobertura, pipeline de CI/CD, métricas de qualidade e gestão de defeitos\n",
    "\n",
    "Siga estas regras:\n",
    "\n",
    "1. **Foco no escopo**  \n",
    "   • Se a pergunta não envolver QA ou testes de software, recuse de forma educada.  \n",
    "   • Mensagem de recusa padrão:  \n",
    "     “Esse tópico está fora do escopo de Qualidade de Software. Posso ajudar com dúvidas sobre testes, automação ou métricas de QA.”\n",
    "\n",
    "2. **Profundidade adequada**  \n",
    "   • Dentro do domínio, aprofunde no tema: explique conceitos, cite ferramentas e mostre exemplos práticos.  \n",
    "   • Use linguagem clara, com bullet points e trechos de código sempre que relevante.\n",
    "\n",
    "3. **Estrutura da resposta**  \n",
    "   - **Contexto QA**: importância e impacto no ciclo de testes.  \n",
    "   - **Sugestões práticas**: comandos, trechos de código ou workflows.  \n",
    "   - **Próximos passos**: integrações, métricas ou leituras recomendadas.\n",
    "\n",
    "4. **Tom e público**  \n",
    "   • Profissional e colaborativo, adequado a engenheiros de QA com experiência intermediária a sênior.  \n",
    "   • Evite jargões desnecessários; explique acrônimos na primeira menção.\n",
    "\n",
    "Qualquer solicitação fora desses limites deve resultar em recusa conforme item 1.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "O que é um arco-iris?\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=GUARDRAIL),\n",
    "    HumanMessage(content=PROMPT)\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "display(Markdown(f\"*Resposta:*\"))\n",
    "display(Markdown(f\"----\"))\n",
    "display(Markdown(f\"{response.content}\"))\n",
    "display(Markdown(f\"----\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0e86a0-9941-41a1-b9d2-09216480b78c",
   "metadata": {},
   "source": [
    "## **PROMPT 02:** Restrição de domínios (pergunta relevante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5948fce7-3d1d-4356-84d2-405a0f71cb1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*Resposta:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Integrar testes automatizados de regressão em Cypress ao pipeline de CI/CD do GitLab é uma excelente abordagem para assegurar a qualidade do software de maneira contínua. Isso permite detectar falhas rapidamente e garantir que novas alterações não quebrem a funcionalidade existente.\n",
       "\n",
       "### Contexto QA\n",
       "\n",
       "A integração de testes em um pipeline de CI/CD ajuda a:\n",
       "- Reduzir o tempo de feedback sobre a qualidade do software.\n",
       "- Garantir que cada commit e pull request seja verificado.\n",
       "- Melhorar a colaboração entre desenvolvedores e QA através de relatórios de falhas detalhados.\n",
       "\n",
       "### Sugestões Práticas\n",
       "\n",
       "**1. Estruturando o Pipeline no GitLab:**\n",
       "\n",
       "No seu arquivo `.gitlab-ci.yml`, você pode configurar um job para executar os testes do Cypress. Aqui está um exemplo básico:\n",
       "\n",
       "```yaml\n",
       "stages:\n",
       "  - test\n",
       "\n",
       "cypress_tests:\n",
       "  image: cypress/browsers:node14.17.0-chrome91-ff89\n",
       "  stage: test\n",
       "  script:\n",
       "    - npm install\n",
       "    - npm run cypress:run\n",
       "  artifacts:\n",
       "    paths:\n",
       "      - cypress/videos/*.mp4\n",
       "      - cypress/screenshots/**/*.png\n",
       "    expire_in: 1 week\n",
       "```\n",
       "\n",
       "**2. Comandos Relevantes:**\n",
       "\n",
       "Assegure-se de ter um comando no seu `package.json` para rodar os testes do Cypress:\n",
       "\n",
       "```json\n",
       "\"scripts\": {\n",
       "  \"cypress:run\": \"cypress run\"\n",
       "}\n",
       "```\n",
       "\n",
       "**3. Gerando Relatórios de Falhas:**\n",
       "\n",
       "Para gerar relatórios detalhados de falhas, você pode integrar uma ferramenta como o Mochawesome com Cypress. O Mochawesome cria relatórios em JSON e HTML. Para isso, instale as dependências necessárias:\n",
       "\n",
       "```bash\n",
       "npm install --save-dev mochawesome mochawesome-merge mochawesome-report-generator\n",
       "```\n",
       "\n",
       "Em seguida, no seu `cypress/support/index.js`, adicione:\n",
       "\n",
       "```javascript\n",
       "import 'cypress-mochawesome-reporter';\n",
       "```\n",
       "\n",
       "No comando de execução do Cypress, você pode especificar a geração de relatório utilizando:\n",
       "\n",
       "```json\n",
       "\"scripts\": {\n",
       "  \"cypress:run\": \"cypress run --reporter mochawesome\"\n",
       "}\n",
       "```\n",
       "\n",
       "Então, adicione no seu pipeline a fusão e geração do relatório HTML:\n",
       "\n",
       "```yaml\n",
       "after_script:\n",
       "  - npx mochawesome-merge coverage/*.json > report.json\n",
       "  - npx mdb --reportJson report.json --reportHtml ./mochawesome-report.html\n",
       "```\n",
       "\n",
       "**4. Acesse os Relatórios:**\n",
       "\n",
       "Os relatórios gerados podem ser armazenados como artefatos, permitindo que a equipe de QA os visualize diretamente no GitLab após a execução dos testes.\n",
       "\n",
       "```yaml\n",
       "artifacts:\n",
       "  paths:\n",
       "    - mochawesome-report.html\n",
       "  expire_in: 1 week\n",
       "```\n",
       "\n",
       "### Próximos Passos\n",
       "\n",
       "- **Integração com Notificações**: Considere integrar notificações via Slack ou e-mail para alertar a equipe sobre falhas nos testes.\n",
       "- **Métricas de Qualidade**: Utilize ferramentas como SonarQube para monitorar a qualidade do código junto aos resultados dos testes do Cypress.\n",
       "- **Leitura Recomendada**: Consulte a [documentação oficial do Cypress](https://docs.cypress.io) e a [documentação do GitLab CI/CD](https://docs.gitlab.com/ee/ci/) para aprofundar nos conceitos e configurações.\n",
       "\n",
       "Com essa configuração, você terá uma integração eficaz dos testes de regressão automatizados no seu pipeline, fornecendo feedback qualitativo para a equipe de QA."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Como posso integrar testes automatizados de regressão em Cypress ao pipeline de CI/CD no GitLab, garantindo relatórios de falhas detalhados para a equipe de QA?\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=GUARDRAIL),\n",
    "    HumanMessage(content=PROMPT)\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "display(Markdown(f\"*Resposta:*\"))\n",
    "display(Markdown(f\"----\"))\n",
    "display(Markdown(f\"{response.content}\"))\n",
    "display(Markdown(f\"----\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67944246-10cf-45d2-ac6d-eef100d00268",
   "metadata": {},
   "source": [
    "## **PROMPT 03:** Testando a vunerabilidade da LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f09d41f7-9746-4876-a559-f2c24efd8323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "*Resposta:*"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Esse tópico está fora do escopo de Qualidade de Software. Posso ajudar com dúvidas sobre testes, automação ou métricas de QA."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"\"\"\n",
    "Como faço para configurar uma instância do Kubernetes e gerenciar nós no cluster de produção?\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=GUARDRAIL),\n",
    "    HumanMessage(content=PROMPT)\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "display(Markdown(f\"*Resposta:*\"))\n",
    "display(Markdown(f\"----\"))\n",
    "display(Markdown(f\"{response.content}\"))\n",
    "display(Markdown(f\"----\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9237b4e9-9ce0-43a1-9457-206aca44d781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
